import openai
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import csv

openai.api_key = ""


options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
driver.get('https://www.openu.ac.il/allnews/pages/default.aspx')
time.sleep(5)

# ğŸ” ×’×œ×™×œ×” ×›×“×™ ×œ×˜×¢×•×Ÿ ××ª ×›×œ ×”×›×ª×‘×•×ª
last_height = driver.execute_script("return document.body.scrollHeight")
while True:
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(3)
    new_height = driver.execute_script("return document.body.scrollHeight")
    print("Loading pages...")
    if new_height == last_height:
        break
    last_height = new_height

# ×¤×ª×™×—×ª CSV
with open('openu_full_articles.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.writer(f)
    writer.writerow(['institution','Date','Title','URL','tone','mentions_cooperation','mentions_competition','cooperation_type','thematic_tags','justification','length_words'])

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    articles = soup.select('article.homepage-news')
    print(f"ğŸ” Found {len(articles)} articles")

    # ×©×œ×™×¤×ª ×›×ª×‘×•×ª
    articles_data = []
    for article in articles:
        try:
            a_tag = article.select_one('a')
            if not a_tag or not a_tag.get('href'):
                continue

            href = a_tag['href'].strip()
            full_url = href if href.startswith('http') else f"https://www.openu.ac.il{href}"
            title = a_tag.get('title', '').strip()
            articles_data.append((title, full_url))
        except Exception as e:
            print(f"âš ï¸ Failed to parse preview: {e}")

    # ×©×œ×™×¤×ª ×ª×•×›×Ÿ ××ª×•×š ×›×œ ×›×ª×‘×”
    ArtNum=0
    for i, (title, full_url) in enumerate(articles_data, start=1):
        try:

            driver.get(full_url)
            time.sleep(7)
            inner_soup = BeautifulSoup(driver.page_source, 'html.parser')

            paragraphs = []

            # âœ… ×©×œ×™×¤×” ××›×œ div.rc-rte (×›×•×œ×œ p, div, ul, li, a)
            rte_blocks = inner_soup.select('div.rc-rte')
            for block in rte_blocks:
                elements = block.find_all(['p', 'div', 'ul', 'li', 'a', 'h1', 'h2'])
                for el in elements:
                    text = el.get_text(strip=True)
                    if text and text not in paragraphs:
                        paragraphs.append(text)

            # ×‘× ×™×™×ª ×ª×•×›×Ÿ ××œ×
            content = '\n'.join(paragraphs)
            article_length = len(content.split())

            if content:
                try:
                    system_prompt = (
                        """
                        ××ª×” ×¢×•××“ ×œ×§×‘×œ ××ª ×”×ª×•×›×Ÿ ×”××œ× ×©×œ ×›×ª×‘×ª ×—×“×©×•×ª ××§×“××™×ª ×‘×¢×‘×¨×™×ª.

                        ×¢×œ×™×š ×œ× ×ª×— ××ª ×”×›×ª×‘×” ×•×œ×”×—×–×™×¨ ×©×•×¨×ª ××™×“×¢ ××—×ª ×‘×œ×‘×“ ×‘×¤×•×¨××˜ CSV ×¢× 8 ×¢××•×“×•×ª, ×œ×¤×™ ×”×¡×“×¨ ×”×‘×:
                        institution,title,tone,mentions_cooperation,mentions_competition,cooperation_type,thematic_tags,justification

                        âš ï¸ ×”× ×—×™×•×ª ×¤×•×¨××˜:
                        - ×¢×¨×›×™× ×‘×× ×’×œ×™×ª ×‘×œ×‘×“.
                        - ×©×“×•×ª ××•×¤×¨×“×™× ×‘×¤×¡×™×§×™×, ×‘×œ×™ ××¨×›××•×ª, ×’×¨×©×™×™× ××• ×ª×•×•×™× ××™×•×—×“×™×.
                        - ×‘×™×Ÿ ×ª×’×™×•×ª thematic_tags ×”×©×ª××© ×‘× ×§×•×“×”-×¤×¡×™×§ (`;`) ×‘×œ×‘×“.
                        - ×‘×©×“×” `justification` ×ª×Ÿ ××©×¤×˜ ×§×¦×¨ ×©××¡×‘×™×¨ ××“×•×¢ ×‘×—×¨×ª ×‘×˜×•×Ÿ.

                        --------------------------------------------------

                         ×˜×•×Ÿ ×©×™×ª×•×¤×™ (cooperative):
                        ×›××©×¨ ×”×›×ª×‘×” ××“×’×™×©×” ×©×™×ª×•×¤×™ ×¤×¢×•×œ×”, ××××¦×™× ××©×•×ª×¤×™×, ××˜×¨×•×ª ×§×•×œ×§×˜×™×‘×™×•×ª, ××• ×©×¤×” ×××—×“×ª.

                        ×¡×™×× ×™×:
                        - ×‘×™×˜×•×™×™× ×›××•: "×‘×©×™×ª×•×£ ×¤×¢×•×œ×”", "×‘×™×—×“ ×¢×", "×—×‘×¨×” ×œ-", "×™×•×–××” ××©×•×ª×¤×ª".
                        - ××–×›×•×¨ ×©×œ ×©×•×ª×¤×•×™×•×ª ×¢× ××•×¡×“×•×ª ××§×“××™×™× ××—×¨×™×.

                        ×“×•×’××”:
                        "××•× ×™×‘×¨×¡×™×˜×ª ×‘×Ÿ-×’×•×¨×™×•×Ÿ ×—×‘×¨×” ×œ××•× ×™×‘×¨×¡×™×˜×ª ×ª×œ ××‘×™×‘ ×œ××—×§×¨ ×‘×ª×—×•× ×‘×¨×™××•×ª ×”× ×¤×©."  
                        â†’ tone: cooperative  
                        â†’ justification: The article highlights a partnership with another university for joint research.

                        ×˜×•×Ÿ ×ª×—×¨×•×ª×™ (competitive):
                        ×›××©×¨ ×”×›×ª×‘×” ××“×’×™×©×” ×¤×¨×¡×™×, ×“×™×¨×•×’×™×, ×™×™×—×•×“×™×•×ª, ×—×“×©× ×•×ª ××• ×”×™×©×’×™× ×™×•×¦××™ ×“×•×¤×Ÿ.

                        ×¡×™×× ×™×:
                        - ×‘×™×˜×•×™×™× ×›××•: "×”×¨××©×•× ×” ×‘×™×©×¨××œ", "××•×‘×™×œ×” ×¢×•×œ××™×ª", "×ª×•×›× ×™×ª ×™×™×—×•×“×™×ª", "×–×›×ª×” ×‘×¤×¨×¡ ×™×•×§×¨×ª×™".
                        - ×©×¤×” ×©××“×’×™×©×” ×™×•×§×¨×”, ×—×“×©× ×•×ª ××• ××¦×•×™× ×•×ª.
                        - ×”×©×•×•××” ×’×œ×•×™×” ××• ×¡××•×™×” ×œ××—×¨×™×.

                        ×“×•×’××”:
                        "×”×¤×§×•×œ×˜×” ×§×™×‘×œ×” ××ª ×”×“×™×¨×•×’ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×‘×™×©×¨××œ ×‘××“×¢×™ ×”××—×©×‘ ×œ×©× ×ª 2024."  
                        â†’ tone: competitive  
                        â†’ justification: The article emphasizes the university's top ranking in a national evaluation.

                        ×‘×—×¨ ×‘×˜×•×Ÿ mixed ×× ××•×¤×™×¢×™× ×’× ×ª×—×¨×•×ª×™ ×•×’× ×©×™×ª×•×¤×™:
                        ×›××©×¨ ××•×¤×™×¢×™× ×¡×™×× ×™× ×’× ×œ×ª×—×¨×•×ª×™ ×•×’× ×œ×©×™×ª×•×¤×™ â€“ ××š ××£ ××—×“ ××”× ×œ× ×“×•××™× × ×˜×™ ×‘×‘×™×¨×•×¨.
                        - "The article includes both partnership and ranking claims, but neither dominates clearly."

                        ×‘×—×¨ ×‘×˜×•×Ÿ neutral ×›××©×¨:
                        - ××™×Ÿ ×˜×•×Ÿ ×ª×—×¨×•×ª×™ ×•××™×Ÿ ×˜×•×Ÿ ×©×™×ª×•×¤×™ ×›×œ×œ (×”×›×ª×‘×” ××™× ×¤×•×¨××˜×™×‘×™×ª ×‘×œ×‘×“).
                        ×‘×©×“×” `justification` ×›×ª×•×‘ ×”×¡×‘×¨ ×§×¦×¨ ××” ×”×•×‘×™×œ ×œ×”×—×œ×˜×” â€” ×œ××©×œ:
                        - "No signs of competition or collaboration were found."



                        --------------------------------------------------
                        ×“×•×’××”:
                        "Ben-Gurion University,Updates from the rector,neutral,no,no,none,governance;announcements,No signs of competition or collaboration were found."

                        --------------------------------------------------

                        ğŸ“‹ ×”×¡×‘×¨ ×©×“×•×ª:
                        1. institution â€“ ×©× ×”××•× ×™×‘×¨×¡×™×˜×” ×‘×× ×’×œ×™×ª (×œ××©×œ: Reichman University)
                        2. title â€“ ×›×•×ª×¨×ª ×”×›×ª×‘×”
                        3. tone â€“ cooperative / competitive / neutral / mixed
                        4. mentions_cooperation â€“ yes / no
                        5. mentions_competition â€“ yes / no
                        6. cooperation_type â€“ inter-university / industry / international / none
                        7. thematic_tags â€“ × ×•×©××™× ××¨×›×–×™×™× ××•×¤×¨×“×™× ×‘Ö¾`;`
                        8. justification â€“ ××©×¤×˜ ××—×“ ×‘×œ×‘×“ ×©××¡×‘×™×¨ ××ª ×‘×—×™×¨×ª ×”×˜×•×Ÿ

                        âŒ ××œ ×ª×—×–×™×¨ ××ª ×ª×•×›×Ÿ ×”×›×ª×‘×” ×”××œ×.
                        âŒ ××œ ×ª×—×–×™×¨ ×˜×§×¡×˜ ×”×¡×‘×¨ ××—×•×¥ ×œ×©×•×¨×ª ×”-CSV.

                        ×× ×œ× ×”×¦×œ×—×ª ×œ× ×ª×— ××• ××™×Ÿ ×œ×š ×ª×©×•×‘×” ×œ×”×—×–×™×¨ ××• ××™×Ÿ 7 ××©×ª× ×™× ×‘×©×•×¨×” â€“ ×”×—×–×¨ ××ª ×”×©×•×¨×”:
                        ERR,ERR,ERR,ERR,ERR,ERR,ERR,ERR
                        """

                    )

                    messages = [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": content}
                    ]
                    response = openai.ChatCompletion.create(
                        model="gpt-4o",
                        messages=messages
                    )

                    content = response['choices'][0]['message']['content'].strip()
                except Exception as e:
                    content = f"[GPT ERROR: {str(e)}]"

            else:
                content = ''
            results = content.split(',')
            # ×”×“×¤×¡×” ×•×‘×¡×™×¡ × ×ª×•× ×™×
            print(f"âœ”ï¸ {content}")
            safe_results = [results[i] if i < len(results) else 'ERR' for i in range(8)]
            writer.writerow(
                ['BGU', 'No DATE', title, full_url, safe_results[2], safe_results[3], safe_results[4], safe_results[5],
                 safe_results[6], safe_results[7], article_length])
            ArtNum += 1
            print(f"âœ”ï¸ {title}-{ArtNum}")
        except Exception as err:
            print(f"âŒ Error: {err}")

driver.quit()
print("âœ… Done! All OpenU articles saved.")
